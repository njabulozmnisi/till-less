# Story 5.2: Savings & Accuracy Analytics

## Status
Draft

## Story
**As a** TillLess analyst,
**I want** dashboards and alerts comparing predicted vs actual spend,
**so that** we can track savings, detect mapping issues, and prioritise manual review.

## Acceptance Criteria
1. Data pipeline computes variance metrics (predicted vs actual totals, item-level mismatches) via SQL views/materialised view or ETL joining optimisation runs and receipts. [Source: docs/prd/10-10-analytics-telemetry.md#10-analytics-telemetry]
2. Metabase or Grafana dashboards visualise savings trends, accuracy %, and top variances by retailer/item with filters for date range and household. [Source: docs/architecture/04-4-component-breakdown.md#48-observability--ops]
3. Alerts trigger when variance exceeds configurable threshold (>5%) for two consecutive runs, notifying Slack/email with remediation guidance. [Source: docs/architecture/09-9-monitoring-alerting.md#9-monitoring--alerting]
4. Analyst workflow surfaces mismatched items for manual review by pushing entries into `product_matching_queue`. [Source: docs/canonical-product-registry.md#4-matching--normalisation-rules-addenda]
5. Documentation covers dashboard interpretation, alert response steps, and variance escalation procedures. [Source: docs/architecture/04-4-component-breakdown.md#48-observability--ops]
6. Automated tests/validation queries verify metrics accuracy and alert thresholds; QA artifacts include dashboard exports and alert screenshots. [Source: docs/architecture/testing-strategy.md#testing-strategy]

## Tasks / Subtasks
- [ ] Data aggregation & storage (AC: 1)
  - [ ] Create SQL view/materialised view in Supabase joining optimisation results, receipts, and variance metrics; schedule refresh (Temporal/cron). [Source: docs/architecture/04-4-component-breakdown.md#48-observability--ops]
  - [ ] Expose Prisma/data-access helper for analytics consumers and document schema. [Source: docs/architecture/source-tree.md#source-tree--module-layout]
- [ ] Dashboard configuration (AC: 2, 5)
  - [ ] Build Metabase/Grafana dashboards with cards for savings trend, variance heatmap, top mismatches; add filters and descriptive text. [Source: docs/prd/10-10-analytics-telemetry.md#10-analytics-telemetry]
  - [ ] Publish read-only links, embed in docs/ops analytics section with screenshots.
- [ ] Alerting pipeline (AC: 3)
  - [ ] Implement scheduled job (GitHub Action or Temporal) evaluating variance threshold, posting Slack alert with recommended actions. [Source: docs/architecture/09-9-monitoring-alerting.md#9-monitoring--alerting]
  - [ ] Provide suppression controls and log outcomes.
- [ ] Analyst tooling integration (AC: 4)
  - [ ] Add admin UI/button to flag mismatched items into `product_matching_queue` with comment, updating backlog for data team. [Source: docs/canonical-product-registry.md#4-matching--normalisation-rules-addenda]
  - [ ] Track action history for audit.
- [ ] Testing & documentation (AC: 5, 6)
  - [ ] Write SQL/unit tests validating variance calculations and threshold logic; add integration test for alert workflow. [Source: docs/architecture/testing-strategy.md#testing-strategy]
  - [ ] Update analyst handbook/runbooks with dashboard interpretation, alert response, and escalation paths; attach QA evidence (dashboard export, alert screenshot).

## Dev Notes
**Dependencies**
- Requires receipt upload pipeline (Story 5.1) and optimisation result storage (Epic 2) to populate variance data.

**Performance**
- Refresh materialised views during low-traffic windows; ensure queries handle growing data (indexes on household, retailer, run date).

**Alert Tuning**
- Start with 5% threshold, allow configuration via environment variable; implement deduping to prevent alert spam.

**Security & Access**
- Restrict dashboards to analysts (BetterAuth roles) and enforce row-level security if exposing raw data. Use signed Metabase links as needed.

### Testing
- Unit tests: SQL variance calculations via dbt/Jest-sql, alert evaluation logic. [Source: docs/architecture/testing-strategy.md#testing-strategy]
- Integration tests: trigger synthetic receipts to ensure alerts fire appropriately and mismatches land in queue.
- Manual QA: capture dashboard exports, alert notifications, and analyst workflow demonstration.
- Key scenarios: variance under threshold, variance spike, repeated spike (alert), mismatched item flagged, dashboard filter usage.

## Change Log
| Date | Version | Description | Author |
| --- | --- | --- | --- |
| 2025-09-28 | v0.1 | Initial draft prepared by Scrum Master | Bob |

## Dev Agent Record
### Agent Model Used

### Debug Log References

### Completion Notes List

### File List

## QA Results
| Date | Reviewer | Outcome | Notes |
| --- | --- | --- | --- |

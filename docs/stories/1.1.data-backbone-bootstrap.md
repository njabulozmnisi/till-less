# Story 1.1: Data Backbone Bootstrap

- **Status:** Draft
- **Epic:** 1 – Data Backbone Foundations
- **Related PRD Sections:** `docs/prd/05-5-scope-phase-1-mvp.md`, `docs/prd/07-7-detailed-requirements.md`, `docs/prd/09-9-data-model-integrations.md`
- **Related Architecture Sections:** `docs/architecture/03-3-high-level-architecture-overview.md`, `docs/architecture/04-4-component-breakdown.md`, `docs/architecture/06-6-technology-stack.md`

## Story Statement
As the TillLess platform operator, I want the Phase 1 canonical product registry schema live and a production-grade Checkers/Sixty60 ingestion loop writing fresh catalogue and price snapshots through the pg-boss queue, so that downstream optimisation can rely on accurate data for the pilot geography.

## Acceptance Criteria
- [ ] Supabase Postgres (staging + prod) updated with migration `20241007_0001_cpr_phase1.sql`; new columns (`price_mode`, `price_per_uom`, loyalty/promo fields, store metadata) verified via SQL introspection queries.
- [ ] Checkers/Sixty60 scraper worker (TypeScript + Playwright) triggered via Temporalite workflow publishes payloads to pg-boss and persists to CPR tables on manual and scheduled runs.
- [ ] Ingestion writes populate `retailer_item` and `retailer_item_price` with ≥500 active SKUs covering staple categories (milk, bread, rice, oil, detergents, nappies, chicken) for at least one Johannesburg store.
- [ ] `content_hash` prevents duplicate writes on consecutive runs; rerunning worker without catalogue changes results in ≤5% new rows.
- [ ] Metrics/logs for workflow execution (duration, SKU count, success/failure) visible in Temporalite UI and forwarded to central log sink (Grafana/Logtail). Alert rule configured for two consecutive failures.
- [ ] Runbook entry documents how to trigger the Checkers ingestion (Temporal CLI and manual pnpm script) and verify data freshness in Postgres.

## Tasks & Subtasks
1. **Apply CPR Phase 1 Migration**
   - Run migration script against staging Supabase Postgres; capture before/after schema snapshot.
   - Repeat for production (or note pending release) once staging signed off.
   - Document verification queries in `db/README.md` (append if needed).
2. **Implement Checkers Scraper Worker**
   - Bootstrap Playwright script per `docs/retailer-scraping-playbook.md` (Sixty60 GraphQL endpoints) using TypeScript + pnpm.
   - Add polite rate limiting, auth token management, and `content_hash` calculation.
   - Package worker for container execution (Dockerfile + Temporal worker registration).
3. **Configure pg-boss Queue & Consumer**
   - Install/initialise `pg-boss` against Supabase Postgres; create dedicated schema and credentials.
   - Implement NestJS queue consumer that maps payloads to CPR schema (parsing promo, loyalty, pack data) via Prisma.
   - Add automated tests covering payload validation and DB insert mapping (using test Postgres database).
4. **Wire Temporalite Workflow**
   - Define TypeScript Temporal workflow/activity to run Checkers worker on configured cadence with retry policy.
   - Register workflow locally (Temporalite) and provide GitHub Actions cron fallback for nightly execution.
5. **Seed Canonical Data**
   - Execute workflow to collect initial dataset for a representative Gauteng store.
   - Validate ≥500 SKUs written with correct `price`, `loyalty_price`, `price_mode`, `availability` using Prisma queries.
   - Spot-check 10 items manually against live site for accuracy.
6. **Observability & Runbook**
   - Emit logs/metrics to Temporalite UI and export structured logs to Grafana/Logtail (include SKU count, scrape timestamp, content-hash stats).
   - Configure alert (Slack webhook) for two consecutive failures or zero SKU output.
   - Update/create ingestion runbook section with commands, Temporal queries, expected outputs, troubleshooting steps.

## Implementation Notes for Dev Agent
- Align strictly with CPR schema (`docs/canonical-product-registry.md`); handle `price_mode` and `price_per_uom` for per-weight items.
- Store Sixty60 credentials in BetterAuth/Secrets manager or Supabase secrets; never log sensitive data.
- Queue payload should include raw fields (`product_name_raw`, `promo_badge_raw`, etc.) for auditing before Prisma persistence.
- Use Prisma batching (`createMany`) to minimise DB round trips while respecting transaction limits.
- Temporalite worker and NestJS consumer should share TypeScript types via a common package.

## Testing & Validation
- Automated: Jest tests for queue consumer mapping, Prisma persistence, and Temporal workflow logic (using Temporal test environment).
- Manual: Trigger workflow twice; confirm second run emits “no change” behaviour. Validate sample entries via SQL/Prisma queries.
- Performance: Ensure end-to-end run completes within configured time window (<10 minutes for 500 SKUs) on Temporalite.

## Dependencies / Sequencing Notes
- Requires Supabase Postgres access, Temporalite environment, and secrets for Sixty60 API/token.
- Downstream optimisation stories depend on this data; schedule first in Epic 1.
- Follow-up stories (1.2–1.5) will onboard additional retailers, automate monitoring dashboards, and integrate receipt feedback.

## QA Handoff Checklist (to be completed by Dev before QA)
- [ ] Story status moved to "Review" with latest test evidence attached.
- [ ] Temporalite workflow run screenshot/log + queue metrics attached.
- [ ] SQL/Prisma queries verifying schema and sample data provided.
- [ ] Runbook link updated and referenced in story comments.

## Implementation Log
| Date | Author | Notes |
| --- | --- | --- |

## QA Results
| Date | Reviewer | Outcome | Notes |
| --- | --- | --- | --- |

## File Tracker
- _To be populated by Dev agent upon implementation._
